#设备数据特征分布差异对联邦学习的影响研究
随着数字化时代的到来，企业可以依据用户数据提供定制化服务，从而增强用户的忠诚度和粘性，因此数据成为企业争抢的资源。但在这个过程中往往会涉及到两个严重的问题，分别是数据孤岛和隐私泄露的问题。针对这两个挑战，联邦学习应运而生。联邦学习允许数据在各个设备上本地处理，在保护隐私的基础上还解决了数据孤岛的问题。尽管联邦学习在隐私保护方面取得了显著进展，但是在处理非独立同分布（Non-IID）数据时仍面临性能挑战。本文首先通过实验验证了设备数据特征分布差异对传统联邦学习算法的负面影响。为解决该问题，本文基于个性化联邦学习框架，采用基于注意力的诱导函数为每个客户端模型分配个性化聚合权重，以使得聚合后的模型更适合各客户端的数据特征分布。实验结果表明，相较于传统联邦学习方法，该个性化联邦学习方法可以有效提升模型在不同数据特征分布设备上的泛化能力。这一成果为解决联邦学习中的数据异质性问题提供了新的思路。
With the advent of the digital era, enterprises can provide customized services based on user data, thereby enhancing user loyalty and stickiness, making data a resource that enterprises compete for. However, this process often involves two serious issues: data silos and privacy breaches. In response to these challenges, federated learning emerged. Federal learning allows data to process local processing on each device, and also solves the problem of data silos on the basis of protecting privacy. Although federated learning has made significant progress in privacy protection, it still faces performance challenges when dealing with Non-Independent and Identically Distributed (Non-IID) data. This article first verifies the negative impact of differences in device data feature distribution on traditional federated learning algorithms through experiments. To solve this problem, this article is based on a personalized federated learning framework and uses an attention based induction function to assign personalized aggregation weights to each client model, so that the aggregated model is more suitable for the data feature distribution of each client. The experimental results show that compared to traditional federated learning methods, this personalized federated learning method can effectively improve the model's generalization ability on devices with different data feature distributions. This achievement provides new insights for solving the issue of data heterogeneity in federated learning.
